{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76ee044",
   "metadata": {},
   "source": [
    "**1.\tCan you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb4ac1",
   "metadata": {},
   "source": [
    "1. In Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length.\n",
    "    > Applications: Speech recognition, machine translation, image captioning and question answering\n",
    "2. The RNN model where we give input a sequence at output comes out to be a single vector.\n",
    "    > Applications: Language Predictor\n",
    "3. The RNN model where input is a single vector and outputs a sequence.\n",
    "    >Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31733c0",
   "metadata": {},
   "source": [
    "**2.\tWhy do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3873301a",
   "metadata": {},
   "source": [
    "1. The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods.\n",
    "2. The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.\n",
    "3. The Encoder-Decoder architecture with recurrent neural networks has become an effective and standard approach for both neural machine translation (NMT) and sequence-to-sequence (seq2seq) prediction in general.\n",
    "4. The key benefits of the approach are the ability to train a single end-to-end model directly on source and target sentences and the ability to handle variable length input and output sequences of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc83ee",
   "metadata": {},
   "source": [
    "**3.\tHow could you combine a convolutional neural network with an RNN to classify videos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bde78",
   "metadata": {},
   "source": [
    "1. CNNs are good with hierarchical or spatial data and extracting unlabeled features. Those could be images or written characters.  CNNs take fixed size inputs and generate fixed size outputs.\n",
    "2. RNNs are good at temporal or otherwise sequential data. Could be letters or words in a body of text, stock market data, or speech recognition.  RNNs can input and output arbitrary lengths of data.\n",
    "3. A video consists of an ordered sequence of frames. Each frame contains spatial information, and the sequence of those frames contains temporal information. To model both of these aspects, we use a hybrid architecture that consists of convolutions (for spatial processing) as well as recurrent layers (for temporal processing). Specifically, we'll use a Convolutional Neural Network (CNN) and a Recurrent Neural Network (RNN) consisting of GRU layers. This kind of hybrid architecture is popularly known as a CNN-RNN.\n",
    "\n",
    "![](https://www.datasciencecentral.com/wp-content/uploads/2021/10/2220288537.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146a0e2",
   "metadata": {},
   "source": [
    "**4.\tWhat are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055e896",
   "metadata": {},
   "source": [
    "1. The static_rnn() function creates an unrolled RNN network by chaining cells. This approach still builds a graph containing one cell per time step. \n",
    "2. With such as large graph, you may even get out-of-memory (OOM) errors during backpropagation (especially with the limited memory of GPU cards), since it must store all tensor values during the forward pass so it can use them to compute gradients during the reverse pass.\n",
    "3. The dynamic_rnn() function uses a while_loop() operation to run over the cell the appropriate number of times\n",
    "4. Conveniently, it also accepts a single tensor for all inputs at every time step and it outputs a single tensor for all outputs at every time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ace21",
   "metadata": {},
   "source": [
    "**5.\tHow can you deal with variable-length input sequences? What about variable-length output sequences?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f3d1b",
   "metadata": {},
   "source": [
    "1. In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length.\n",
    "2. Contrived Sequence Problem, Sequence Padding: Pre-Sequence Padding, Post-Sequence Padding,, Sequence Truncation: Pre-Sequence Truncation, Post-Sequence Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3dbdf",
   "metadata": {},
   "source": [
    "**6.\tWhat is a common way to distribute training and execution of a deep RNN across multiple GPUs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98449dd6",
   "metadata": {},
   "source": [
    "1. There are generally two ways to distribute computation across multiple devices: Data parallelism and Model parallelism\n",
    "2. Data parallelism, where a single model gets replicated on multiple devices or multiple machines. Each of them processes different batches of data, then they merge their results. There exist many variants of this setup, that differ in how the different model replicas merge results, in whether they stay in sync at every batch or whether they are more loosely coupled, \n",
    "3. Model parallelism, where different parts of a single model run on different devices, processing a single batch of data together. This works best with models that have a naturally-parallel architecture, such as models that feature multiple branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77ac36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
